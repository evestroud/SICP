https://sarabander.github.io/sicp/html/1_002e2.xhtml#g_t1_002e2

### 1.2.1 - Linear Recursion and Iteration
* e.g. simple factorial
	* n! = n * (n - 1)! 
		* where 1! = 1
```
(define (factorial n)
	(if (= n 1) 
		1 
		(* n (factorial (- n 1)))))
```
* another approach to factorial
	* multiply 1 * 2 * 3... until reaching n
		* to maintain running product, use a counter that counts from 1 to n alongside the product
		* product = counter * product
		* counter = counter + 1
		* n! = the value of the product when the counter exceeds n
```
(define (factorial n)
  (define (iter product counter)
    (if (> counter n)
        product
        (iter (* counter product)
              (+ counter 1))))
  (iter 1 1))
```
* first example
	* expansion of chain of deferred operations
	* contraction after reaching base case
		* operations are performed on the next result in the chain until chain is fully reduced
	* "recursive process"
		* requires interpreter to keep track of operations to be performed later on
	* in `factorial`, both the number of steps required to computer the result and the length of the chain of deferred multiplications grows in proportion to `n` (the size of the input)
			* "linear recursive process"
* second example
	* does not grow and shrink
		* only need to keep track of `product`, `counter`, and `n`
	* "iterative process"
		* process whos state can be summarized by a fixed number of "state variables"
			* with fixed rules on how the variables should be updated
			* + end test that specifies conditions under which the process should terminate
	* inf `factorial` the number of steps required grows linearly but size of state remains constant
		* "linear iterative process"
* contrasting the two
	* iterative
		* program variables provide a complete description of the state of the process at any point
	* recursive
		* interpreter stores "hidden" information in the call stack
		* the longer the chain, the more information must be maintained (space complexity)
* recursive process vs recursive procedure
	* recursive procedure
		* syntactic fact that the procedure definition refers to itself
			* directly or indirectly 
	* recursive process
		* discussing how the process evolves, not syntax
	* iterative recursion
		* definition is recursive
		* process is iterative (fully captured by state variables)
* in many languages, recursive definitions always produce stack frames
	* even if process described is iterative, will still consume memory proportional to number of calls & risk stack overflow
		* these languages require explicitly calling iterative constructs (loops)
	* Scheme does not have this problem or these constructs
		* (macros with similiar functionality and semantics can exist tho)
		* can execute iterative processes in constant space even if defined recursively
		* "tail recursion"

* Exercise 1.9
first -
```
(+ 4 5)
(inc (+ 3 5))
(inc (inc (+ 2 5)))
(inc (inc (inc (+ 1 5))))
(inc (inc (inc (inc (+ 0 5)))))
(inc (inc (inc (inc 5))))
(inc (inc (inc 6)))
(inc (inc 7))
(inc 8)
9
```
* recursive because it has to wait until the recursive call completes before it can finish its operations

* second 
```
(+ 4 5)
(+ 3 6)
(+ 2 7)
(+ 1 8)
(+ 0 9)
9
```
* iterative because it stores its state in a constant number of variables and is defined with tail recursion

Exercise 1.10
```
> (A 1 10)
1024
> (A 2 4)
65536
> (A 3 3)
65536
```
* (f n) = 2n
* (g n) = 2^n
* (h n) = 2^2^n

Exercise 1.13
* don't know enough math or proofs for this

Exercise 1.14
* used ,trace
* space - maximum number of frames is proportional to the value of `amount
* time - maxmimum number of calls is exponential (2^n) to the value of `amount

Exercise 1.15
1. 5 - see 1-2.scm
2. I thought it looked log -ish but idk how to solve this kind of thing so I looked it up and it is log bc of how the input is divided by three in each recursive call
	1. i was distracted by trying to figure out what `p` was doing

Exercise 1.20
* substitution order - 4 calls
* normal order - 10 calls
	* i believe the version on SICP-solutions is incorrect because it expands every recursive call with no way of knowing when to stop
	* mine stops the expansion at the level of each call

Exercise 1.21
* 199 - 199
* 1999 - 1999
* 19999 - 7

Exercise 1.22
`>`1000
* 1009 - 2.86102294921875e-6
* 1013 - 2.1457672119140625e-6
* 1019 - 3.0994415283203125e-6
`>`10000
* 10007 - 6.9141387939453125e-6
* 10009 - 7.152557373046875e-6
* 10037 - 7.867813110351562e-6
`>`100000
* 100003 - 1.9788742065429688e-5
* 100019 - 2.002716064453125e-5
* 100043 - 1.9788742065429688e-5

The square root of 10 is around 3.16. Increasing the size of primes being tested by an order of 10 roughly increases the time it takes to calculate by 3. This is compatible with the notion that programs run in time proportional to the number of steps required in computation.

Exercise 1.23
`>` 1000
1009 - 3.0994415283203125e-6
1013 - 1.9073486328125e-6
1019 - 1.9073486328125e-6
`>` 10000
10007 - 4.0531158447265625e-6
10009 - 4.0531158447265625e-6
10037 - 4.0531158447265625e-6
`>` 100000
100003 - 1.0967254638671875e-5
100019 - 1.0013580322265625e-5
100043 - 1.0013580322265625e-5

The ratio between speed tests with the two versions of `smallest-divisor` appears to be around 2, with the difference being more noticeable and less varied on tests of larger numbers. I believe this is the result of the smaller numbers computing too quickly for the timer to measure accurately.

Exercise 1.24

Expected: Increasing the size of n by a factor of 10 will increase the time to run by the same amount for each increase in magnitude.

`>` 1000
1009 - 1.9073486328125e-6
1013 - 2.1457672119140625e-6
1019 - 2.86102294921875e-6
`>` 10000
10007 - 4.0531158447265625e-6
10009 - 5.9604644775390625e-6
10037 - 6.198883056640625e-6
`>` 100000
100003 - 1.0967254638671875e-5
100019 - 1.0967254638671875e-5
100043 - 1.2874603271484375e-5

The timer results are noisy but appear to increase by 4e-6 for each increment in magnitude.


Exercise 1.25

Alyssa's expmod will finish computing in the same number of steps as the version from the textbook, but will produce much larger numbers in the intermediary steps. The speed tests from the above exercises runs in a very similar amount of time with the modified expmod so the larger intermediate numbers do not have an effect at this scale, but it is likely once Scheme's number system is pushed into more complex representations of digits it will be slower to perform these computations.

Exercise 1.26

Louis's expmod contains duplicate calculation in order to use * instead of square.

Exercise 1.27
```
scheme@(guile-user) [12]> (map fermat-comprehensive '(561 1105 1729 2465 2821 6601))
$43 = (#t #t #t #t #t #t)
scheme@(guile-user) [12]> (map smallest-divisor '(561 1105 1729 2465 2821 6601))
$44 = (3 5 7 5 7 7)
```

Exercise 1.28

```
(map miller-rabin '(561 1105 1729 2465 2821 6601))
$20 = (#f #f #f #f #f #f)
```
